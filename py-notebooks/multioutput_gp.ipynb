{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "from  matplotlib import pyplot as plt\n",
    "sns.set(font_scale=1.1, style=\"white\",  #palette=\"viridis\", \n",
    "        rc={'font.size': 16, 'figure.figsize': (7,4), 'axes.grid': True, 'lines.linewidth':2.0, \n",
    "            'grid.color': '.8', 'grid.linewidth': 0.5,})\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPy\n",
      "  Downloading GPy-1.5.6.tar.gz (820kB)\n",
      "\u001b[K    100% |################################| 829kB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): numpy>=1.7 in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from GPy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): scipy>=0.16 in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from GPy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from GPy)\n",
      "Collecting paramz>=0.6.9 (from GPy)\n",
      "  Downloading paramz-0.7.3.tar.gz (75kB)\n",
      "\u001b[K    100% |################################| 81kB 5.4MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): decorator>=4.0.10 in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from paramz>=0.6.9->GPy)\n",
      "Building wheels for collected packages: GPy, paramz\n",
      "  Running setup.py bdist_wheel for GPy ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/86/ed/02/3b671673c80d587be399021cef8ef4ad80cfe1bfcae16a1f9a\n",
      "  Running setup.py bdist_wheel for paramz ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/66/11/71/e91133fb7c1720f91f9cbd13e1d8d7f39a9359c9068664dc6f\n",
      "Successfully built GPy paramz\n",
      "Installing collected packages: paramz, GPy\n",
      "Successfully installed GPy-1.5.6 paramz-0.7.3\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz\n",
      "Requirement already satisfied (use --upgrade to upgrade): scikit-learn in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages (from sklearn)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/d7/db/a3/1b8041ab0be63b5c96c503df8e757cf205c2848cf9ef55f85e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Cloning into 'DTR'...\n",
      "remote: Counting objects: 410, done.\u001b[K\n",
      "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
      "remote: Total 410 (delta 23), reused 0 (delta 0), pack-reused 364\u001b[K\n",
      "Receiving objects: 100% (410/410), 158.35 MiB | 47.48 MiB/s, done.\n",
      "Resolving deltas: 100% (224/224), done.\n",
      "Checking connectivity... done.\n",
      "Already up-to-date.\n"
     ]
    }
   ],
   "source": [
    "!pip install GPy \n",
    "!pip install sklearn\n",
    "import GPy as gpy\n",
    "!git clone https://github.com/bestxolodec/DTR.git\n",
    "!cd DTR; git pull "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/ipaulo/yandexDisk/DIPLOMA/CODE/py-src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itr import * \n",
    "# import rpy2.robjects as ro\n",
    "# import rpy2\n",
    "# ro.r.source(\"/Users/ipaulo/yandexDisk/DIPLOMA/CODE/src/clean_sources.R\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y = np.load(\"../data/sarcos/Xtr.npy\"),  np.load(\"../data/sarcos/Ytr.npy\")\n",
    "rng = np.random.RandomState(777)\n",
    "n_train, n_test, n_val = 5000, 200, 100\n",
    "shuffle_idxs = np.arange(X.shape[0])\n",
    "np.random.shuffle(shuffle_idxs) \n",
    "n_restarts = 1\n",
    "Xtr, Xts, Xvl, _ = np.split(X[shuffle_idxs, :], np.cumsum([n_train, n_test, n_val]))\n",
    "Ytr, Yts, Yvl, _ = np.split(Y[shuffle_idxs, :], np.cumsum([n_train, n_test, n_val]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simple miltioutput GP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mogp_score(preds, test):\n",
    "    \"\"\"return mean reward â aka mean squared euclidian distance\"\"\"\n",
    "    if isinstance(test, dict):\n",
    "        return np.square(test[\"optimal.treatment\"] - preds).sum(axis=1).mean()\n",
    "    else:\n",
    "        return np.square(Yts - preds).sum(axis=1).mean()\n",
    "    \n",
    "def pred_value(preds, test):\n",
    "    return - get_mogp_score(preds, test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import clone\n",
    "\n",
    "class BaselineModel(object):\n",
    "    def __init__(self, *args, **kwargs): \n",
    "        self.m = LinearRegression(*args, **kwargs)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.models = [clone(self.m).fit(X, Y[:, i]) for i in range(Y.shape[1])]\n",
    "        return self\n",
    "        \n",
    "    def predict(self, Xts):\n",
    "        return np.hstack([m.predict(Xts).reshape(-1,1) for m in self.models])\n",
    "    \n",
    "    def get_score(self, Xts, Yts):\n",
    "        return np.square(Yts - self.predict(Xts)).sum(axis=1).mean()\n",
    "    \n",
    "    def get_rewards_for(self, Xts, Yts):  \n",
    "        return - np.square(Yts - self.predict(Xts)).sum(axis=1).reshape(-1,1)\n",
    "        # TODO: normal shaped alternative \n",
    "        return - np.log(np.square(Yts - self.predict(Xts)).sum(axis=1).reshape(-1,1))\n",
    "    \n",
    "    def build_dataset(self, Xtr, Ytr):\n",
    "        df = pd.DataFrame(np.hstack([Xtr, self.predict(Xtr), self.get_rewards_for(Xtr, Ytr)]))\n",
    "        df.columns = np.hstack([[\"C{}\".format(i) for i in range(Xtr.shape[1])], \n",
    "                                [\"A{}\".format(i) for i in range(Ytr.shape[1])],\n",
    "                                [\"R\"]]) \n",
    "        return df\n",
    "\n",
    "    def get_dataset_in_dict(self, Xtr, Ytr):\n",
    "        return {\"covariates\": Xtr, \"treatment\": self.predict(Xtr), \n",
    "                \"reward\": self.get_rewards_for(Xtr, Ytr), \"optimal.treatment\": Ytr}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bm = BaselineModel(n_jobs=-1).fit(X, Y)\n",
    "train = bm.get_dataset_in_dict(Xtr, Ytr)\n",
    "test = bm.get_dataset_in_dict(Xts, Yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "s_factors_percs = np.arange(.5,1, .01)\n",
    "s_factors = sp.stats.norm.ppf(s_factors_percs) # 50 factors evenly splitted\n",
    "granularity = 50 \n",
    "fit_params = {\"mean_fn\": False, \"n_restarts\": 1, \"verbose\":False, \n",
    "              \"robust\":True, \"normalize\": False}\n",
    "preds, v, m = fit_and_predict(train, test, granularity, s_factors, pred_value, fit_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Simple miltioutput GP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "k = gpy.kern.RBF(21)\n",
    "# m = gpy.models.GPRegression(Xtr, Ytr, kernel=k) \n",
    "m = gpy.models.SparseGPRegression(Xtr, Ytr, kernel=k, num_inducing=2000) \n",
    "m.optimize_restarts(num_restarts=n_restarts, verbose=False, robust=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_mogp_score(m.predict(Xts)[0], Yts) # 2k inducing, 10k train & 10k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.035417479278109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mogp_score(m.predict(Xts)[0], Yts) # 1k inducing, 10k train & 10k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.676514221977374"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mogp_score(m.predict(Xts)[0], Yts) # 7k train & 10k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.705097341917799"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mogp_score(m.predict(Xts)[0], Yts) # 5k train & 10k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.73352777260969"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mogp_score(m.predict(Xts)[0], Yts) # 1k train & 10k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.895384276908555"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mogp_score(m.predict(Xts)[0], Yts) # 1k inducing on 10k train & 10k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.481604519136983"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mogp_score(m.predict(Xts)[0], Yts) # 500 inducing on 5k train & 5k test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.99679684192976"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mogp_score(m.predict(Xts)[0], Yts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coregionalized regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = GPy.util.multioutput.ICM(input_dim=1,num_outputs=2,kernel=GPy.kern.Bias(input_dim=1))\n",
    "m = GPy.models.GPCoregionalizedRegression(X_list=[X1,X2],Y_list=[Y1,Y2],kernel=kernel)\n",
    "m['.*bias.var'].constrain_fixed(1) #B.kappa now encodes the variance.\n",
    "m['.*W'].constrain_fixed(0)\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = GPy.kern.Matern32(1)\n",
    "icm = GPy.util.multioutput.ICM(input_dim=1,num_outputs=2,kernel=K)\n",
    "\n",
    "m = GPy.models.GPCoregionalizedRegression([X1,X2],[Y1,Y2],kernel=icm)\n",
    "m['.*Mat32.var'].constrain_fixed(1.) #For this kernel, B.kappa encodes the variance now.\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import  repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_output = 7\n",
    "icm = gpy.util.multioutput.ICM(input_dim=21,num_outputs=n_output,kernel=gpy.kern.RBF(21))\n",
    "m = gpy.models.GPCoregionalizedRegression(list(repeat(Xtr, n_output)), np.split(Ytr, 7, axis=1), kernel=icm)\n",
    "m.optimize()\n",
    "# prediction data should include number of component\n",
    "m.predict(list(repeat(Xtr, n_output))) # this will fail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
